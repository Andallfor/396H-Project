@article{classifier,
    author = {Mochtak, Michal},
    title = {Chasing the authoritarian spectre: Detecting authoritarian discourse with large language models},
    journal = {European Journal of Political Research},
    volume = {64},
    number = {3},
    pages = {1304-1325},
    keywords = {detecting authoritarianism, deep learning, model, political discourse, authoritarian discourse},
    doi = {https://doi.org/10.1111/1475-6765.12740},
    url = {https://ejpr.onlinelibrary.wiley.com/doi/abs/10.1111/1475-6765.12740},
    eprint = {https://ejpr.onlinelibrary.wiley.com/doi/pdf/10.1111/1475-6765.12740},
    abstract = {Abstract The paper introduces a deep-learning model fine-tuned for detecting authoritarian discourse in political speeches. Set up as a regression problem with weak supervision logic, the model is trained for the task of classification of segments of text for being/not being associated with authoritarian discourse. Rather than trying to define what an authoritarian discourse is, the model builds on the assumption that authoritarian leaders inherently define it. In other words, authoritarian leaders talk like authoritarians. When combined with the discourse defined by democratic leaders, the model learns the instances that are more often associated with authoritarians on the one hand and democrats on the other. The paper discusses several evaluation tests using the model and advocates for its usefulness in a broad range of research problems. It presents a new methodology for studying latent political concepts and positions as an alternative to more traditional research strategies.},
    year = {2025}
}

@article{pushshift,
    author       = {Jason Baumgartner and Savvas Zannettou and Brian Keegan and Megan Squire and Jeremy Blackburn},
    title        = {The Pushshift Reddit Dataset},
    journal      = {CoRR},
    volume       = {abs/2001.08435},
    year         = {2020},
    url          = {https://arxiv.org/abs/2001.08435},
    eprinttype    = {arXiv},
    eprint       = {2001.08435},
    timestamp    = {Fri, 24 Jan 2020 15:00:57 +0100},
    biburl       = {https://dblp.org/rec/journals/corr/abs-2001-08435.bib},
    bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@misc{dump,
    title= {Reddit comments/submissions 2005-06 to 2025-06},
    journal= {},
    author= {stuck\_in\_the\_matrix and Watchful1 and RaiderBDev},
    year= {2025},
    url= {https://academictorrents.com/details/30dee5f0406da7a353aff6a8caa2d54fd01f2ca1},
    abstract= {Reddit comments and submissions from 2005-06 to 2025-06 collected by pushshift and u/RaiderBDev. These are zstandard compressed ndjson files. Example python scripts for parsing the data can be found here https://github.com/Watchful1/PushshiftDumps The more recent dumps are collected by u/RaiderBDev},
    keywords= {'reddit'},
    terms= {},
    license= {},
    superseded= {}
}

@inproceedings{reddit-toxicity,
    author = {Almerekhi, Hind and Jansen, Supervised by Bernard J. and Kwak, co-supervised by Haewoon},
    title = {Investigating Toxicity Across Multiple Reddit Communities, Users, and Moderators},
    year = {2020},
    isbn = {9781450370240},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3366424.3382091},
    doi = {10.1145/3366424.3382091},
    abstract = {Online platforms like Reddit enable users to build communities and converse about diverse topics and interests. However, with the increasing number of users that post disturbing comments containing profanity, harassment, and hate speech, otherwise known as toxic comments. Moderators often struggle with managing the safety of discussions in online communities. To address these issues, we need to detect toxic comments and the root causes of toxicity in discussion threads, i.e., toxicity triggers. Additionally, we need to investigate the toxic posting behavior of users to understand how it differs across online communities and consolidate our findings with moderators from Reddit. In this work, we present our approach, which builds on state-of-the-art methods of toxic comment and toxicity trigger detection. Lastly, we present our research findings of investigating toxicity across users and moderators on Reddit.},
    booktitle = {Companion Proceedings of the Web Conference 2020},
    pages = {294–298},
    numpages = {5},
    keywords = {Reddit, discussion threads, online communities, toxicity, trigger detection},
    location = {Taipei, Taiwan},
    series = {WWW '20}
}

@article{federalist,
    author = {Vincent Marrazzo},
    title = {The Federalists of the Internet? What Online Platforms can Learn From Reddit’s Decentralized Content Moderation Scheme},
    year = {2023},
    publisher = {University of Nebraska-Lincoln},
    journal = {Nebraska Law Review},
    url = {https://lawreview.unl.edu/federalists-internet-what-online-platforms-can-learn-reddits-decentralized-content-moderation/}
}

@article{communists,
    author = {Joshua Hendricks},
    year = {2022},
    title = {ALT-RIGHT OF THE\_DONALD AND AUTHORITARIAN COMMUNISTS ON REDDIT: INTERNET MEMES TO BUILD COMMUNITY},
    journal = {Aquila},
    publisher = {The University of Southern Mississippi},
    url = {https://aquila.usm.edu/masters_theses/925/}
}

% Template: https://www.usenix.org/conferences/author-resources/paper-templates
\documentclass[letterpaper,twocolumn,10pt]{article}
\usepackage{usenix2019_v3}

% to be able to draw some self-contained figs
\usepackage{tikz}
\usepackage{amsmath}

% inlined bib file
\usepackage{filecontents}

\begin{filecontents}[overwrite]{\jobname.bib}
@article{classifier,
    author = {Mochtak, Michal},
    title = {Chasing the authoritarian spectre: Detecting authoritarian discourse with large language models},
    journal = {European Journal of Political Research},
    volume = {64},
    number = {3},
    pages = {1304-1325},
    keywords = {detecting authoritarianism, deep learning, model, political discourse, authoritarian discourse},
    doi = {https://doi.org/10.1111/1475-6765.12740},
    url = {https://ejpr.onlinelibrary.wiley.com/doi/abs/10.1111/1475-6765.12740},
    eprint = {https://ejpr.onlinelibrary.wiley.com/doi/pdf/10.1111/1475-6765.12740},
    abstract = {Abstract The paper introduces a deep-learning model fine-tuned for detecting authoritarian discourse in political speeches. Set up as a regression problem with weak supervision logic, the model is trained for the task of classification of segments of text for being/not being associated with authoritarian discourse. Rather than trying to define what an authoritarian discourse is, the model builds on the assumption that authoritarian leaders inherently define it. In other words, authoritarian leaders talk like authoritarians. When combined with the discourse defined by democratic leaders, the model learns the instances that are more often associated with authoritarians on the one hand and democrats on the other. The paper discusses several evaluation tests using the model and advocates for its usefulness in a broad range of research problems. It presents a new methodology for studying latent political concepts and positions as an alternative to more traditional research strategies.},
    year = {2025}
}
@article{pushshift,
    author       = {Jason Baumgartner and Savvas Zannettou and Brian Keegan and Megan Squire and Jeremy Blackburn},
    title        = {The Pushshift Reddit Dataset},
    journal      = {CoRR},
    volume       = {abs/2001.08435},
    year         = {2020},
    url          = {https://arxiv.org/abs/2001.08435},
    eprinttype    = {arXiv},
    eprint       = {2001.08435},
    timestamp    = {Fri, 24 Jan 2020 15:00:57 +0100},
    biburl       = {https://dblp.org/rec/journals/corr/abs-2001-08435.bib},
    bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@article{dump,
    title= {Reddit comments/submissions 2005-06 to 2025-06},
    journal= {},
    author= {stuck\_in\_the\_matrix and Watchful1 and RaiderBDev},
    year= {},
    url= {https://academictorrents.com/details/30dee5f0406da7a353aff6a8caa2d54fd01f2ca1},
    abstract= {Reddit comments and submissions from 2005-06 to 2025-06 collected by pushshift and u/RaiderBDev. These are zstandard compressed ndjson files. Example python scripts for parsing the data can be found here https://github.com/Watchful1/PushshiftDumps The more recent dumps are collected by u/RaiderBDev},
    keywords= {'reddit'},
    terms= {},
    license= {},
    superseded= {}
}
@inproceedings{reddit-toxicity,
    author = {Almerekhi, Hind and Jansen, Supervised by Bernard J. and Kwak, co-supervised by Haewoon},
    title = {Investigating Toxicity Across Multiple Reddit Communities, Users, and Moderators},
    year = {2020},
    isbn = {9781450370240},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3366424.3382091},
    doi = {10.1145/3366424.3382091},
    abstract = {Online platforms like Reddit enable users to build communities and converse about diverse topics and interests. However, with the increasing number of users that post disturbing comments containing profanity, harassment, and hate speech, otherwise known as toxic comments. Moderators often struggle with managing the safety of discussions in online communities. To address these issues, we need to detect toxic comments and the root causes of toxicity in discussion threads, i.e., toxicity triggers. Additionally, we need to investigate the toxic posting behavior of users to understand how it differs across online communities and consolidate our findings with moderators from Reddit. In this work, we present our approach, which builds on state-of-the-art methods of toxic comment and toxicity trigger detection. Lastly, we present our research findings of investigating toxicity across users and moderators on Reddit.},
    booktitle = {Companion Proceedings of the Web Conference 2020},
    pages = {294–298},
    numpages = {5},
    keywords = {Reddit, discussion threads, online communities, toxicity, trigger detection},
    location = {Taipei, Taiwan},
    series = {WWW '20}
}
@article{federalist,
    author = {Vincent Marrazzo},
    title = {The Federalists of the Internet? What Online Platforms can Learn From Reddit’s Decentralized Content Moderation Scheme},
    year = {2023},
    publisher = {University of Nebraska-Lincoln},
    journal = {Nebraska Law Review},
    url = {https://lawreview.unl.edu/federalists-internet-what-online-platforms-can-learn-reddits-decentralized-content-moderation/}
}
@article{communists,
    author = {Joshua Hendricks},
    year = {2022},
    title = {ALT-RIGHT OF THE\_DONALD AND AUTHORITARIAN COMMUNISTS ON REDDIT: INTERNET MEMES TO BUILD COMMUNITY},
    journal = {Aquila},
    publisher = {The University of Southern Mississippi},
    url = {https://aquila.usm.edu/masters_theses/925/}
}
\end{filecontents}

%-------------------------------------------------------------------------------
\begin{document}
%-------------------------------------------------------------------------------

%don't want date printed
\date{}

% make title bold and 14 pt font (Latex default is non-bold, 16 pt)
\title{\Large \bf Usage of Authoritarian Language in Reddit Community Moderators}

\author{ % alphabetical
{\rm David Li}\\
dl1@terpmail.umd.edu
\and
{\rm Kyle Lin}\\
klin1215@terpmail.umd.edu
\and
{\rm Leo Wang}\\
leowang@terpmail.umd.edu
}

\maketitle

%-------------------------------------------------------------------------------
\section{Motivation}
%-------------------------------------------------------------------------------

% What is it you are trying to solve?
% Why is it important?
% What is the question that this is trying to solve?

Authoritarianism is a common field of research, especially in the context of global politics and leaders. However, understanding how it propagates in and is used by the common person is understudied. To this end, this project will be analyzing the usage of authoritarian language by community (subreddit) moderators across Reddit. The bulk of the work will be testing for correlations to a variety secondary factors, including but not limited to: size of subreddit, number of subreddits moderated, comparison to the general non-moderator population (globally and within their specific subreddit), differences in interactions with subreddits the user does/does not moderate, and how active a moderator is. This offers insights on the psychological aspects of holding a position of power in an online community and how it is reflected in their diction.

% TODO:
% This is certainly a bit of stretch and arguably we can't actually make these conclusions with full confidence
% However I'm pretty sure we need more of a justification than just "its cool and interesting"
Language will be classified by its relation to the language used by commonly recognized political authoritarian figures. This allows the paper to test whether traditional authoritarian language maps to the power dynamics present within subreddits, and if so, what factors could cause the common person to trend towards authoritarian practices.

%-------------------------------------------------------------------------------
\section{Prior Work}
%-------------------------------------------------------------------------------

% Nothing in depth at this time (that comes with the Intermediate report writeup), but at least a perusal of what you think are the most relevant papers.
This work is centered around the application of an existing authoritarian language classifier~\cite{classifier}. There is also an existing corpus of work surrounding the Reddit userbase, such as Almerekhi's work on categorizing toxicity~\cite{reddit-toxicity} or Marrazzo's study showing how Reddit's decentralized moderation practices (that is, delegating subreddit moderation to community moderators) mirrors a federalist governmental system~\cite{federalist}. This is similar in nature to this project's goal of comparing moderator authoritarian language to the global authoritarian discourse. Finally, Hendricks has examined how self-proclaimed "authoritarianist communists" users define authoritarianism~\cite{communists}.

%-------------------------------------------------------------------------------
\section{Methodology}
%-------------------------------------------------------------------------------

% Low-level details aren't strictly needed at this time, but what broadly do you intend to do? Create a new tool? Collect a new dataset? Analyze and existing dataset?

The central work of this project is analyzing existing databases and supplementing it as needed. Authoritarian language of a user will be sourced from their comments and posts and measured through an existing authoritarian language classifier~\cite{classifier}. These comments and posts will be sourced through the Pushshift comment dumps and its related API~\cite{pushshift, dump}, with additional required metadata gathered either through other such databases or manually scraped.

Text from the Pushshift comment dumps can then be measured for authoritarian language using the aforementioned classifier to test and draw conclusions. Much of this work will consist of analyzing and testing comments and posts from users who meet specific criteria against those from Reddit moderators.

%-------------------------------------------------------------------------------
\section{Evaluation}
%-------------------------------------------------------------------------------

% What are your metrics for success? Performance? Privacy? Predictive ability of a new model?
% Will you be comparing to any other prior approaches?
Because this is an open-ended, exploratory problem, evaluation will primarily be based on how holistic the resultant model is (i.e. incorporating as many secondary variables as possible). Additionally, evaluation will be based on the confidence level of the correlation of variables in the resultant model, as well as how reasonable the results appear when compared to a smaller scale manual inspection. The final goal is to be able to build a conclusion about the trends of authoritarian language in subreddit moderators.

\bibliographystyle{plain}
\bibliography{\jobname}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\end{document}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%  LocalWords:  endnotes includegraphics fread ptr nobj noindent
%%  LocalWords:  pdflatex acks